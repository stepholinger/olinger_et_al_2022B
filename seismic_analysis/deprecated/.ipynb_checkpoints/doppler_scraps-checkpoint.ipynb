{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa32be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Estimate rift tip velocity using Doppler shift between local stations and each regional station\n",
    "\n",
    "'''\n",
    "\n",
    "# read data\n",
    "resp = \"VEL\"\n",
    "component = \"R\"\n",
    "st = obspy.read(\"data/MSEED/no_IR/*/*/2012-05-09*\"+resp+\"*\")\n",
    "\n",
    "# set frequency band for analysis\n",
    "freq = [1,5]\n",
    "fs = freq[1]*2\n",
    "\n",
    "# select, filter, and trim regional data\n",
    "regional_stations = ['DNTW','UPTW','THUR']\n",
    "regional_network = 'YT'\n",
    "st_regional = obspy.Stream()\n",
    "for stat in regional_stations:\n",
    "    st_regional += st.select(station=stat)\n",
    "st_regional = taper_and_filter(st_regional,0.05,\"bandpass\",freq)\n",
    "st_regional.resample(fs)\n",
    "\n",
    "# select, filter, and trim local data\n",
    "local_stations = ['PIG2']\n",
    "local_network = 'XC'\n",
    "st_local = obspy.Stream()\n",
    "for stat in local_stations:\n",
    "    st_local += st.select(station=stat)\n",
    "st_local = taper_and_filter(st_local,0.05,\"bandpass\",freq)\n",
    "st_local.resample(fs)\n",
    "\n",
    "# make object for storing values needed for Doppler analysis\n",
    "metadata = {}\n",
    "stations = local_stations + regional_stations\n",
    "for stat in stations:\n",
    "    metadata[stat] = {}\n",
    "    if stat in local_stations:\n",
    "        metadata[stat]['network'] = local_network\n",
    "    if stat in regional_stations:\n",
    "        metadata[stat]['network'] = regional_network\n",
    "        \n",
    "# select time window at local stations for Doppler analysis\n",
    "starttime = obspy.UTCDateTime(2012,5,9,18,3)\n",
    "endtime = obspy.UTCDateTime(2012,5,9,18,6)\n",
    "\n",
    "# define rift start and end positions in longitude and latitude\n",
    "rift_start_lon_lat = [-101.224, -74.867]\n",
    "rift_end_lon_lat = [-101.16, -74.955]\n",
    "\n",
    "# set phase velocity\n",
    "phase_velocity = 4000\n",
    "\n",
    "# convert rift endpoints to epsg:3245\n",
    "rift_start_x_y = get_crs_locations(np.array([rift_start_lon_lat]),\"EPSG:3245\").flatten()\n",
    "rift_end_x_y = get_crs_locations(np.array([rift_end_lon_lat]),\"EPSG:3245\").flatten()\n",
    "\n",
    "# get angle of rift propagation\n",
    "propagation_angle = np.arctan2(rift_start_x_y[1]-rift_end_x_y[1],rift_start_x_y[0]-rift_end_x_y[0])*180/np.pi\n",
    "\n",
    "# get useful metadata for Doppler analysis\n",
    "for stat in stations:\n",
    "    # get station locations\n",
    "    lon_lat = get_station_lon_lat(\"data/XML/\",[metadata[stat]['network']],[stat])\n",
    "    x_y = get_crs_locations(lon_lat,\"epsg:3245\")[0]\n",
    "    metadata[stat]['lon lat'] = lon_lat\n",
    "    metadata[stat]['x y'] = x_y\n",
    "\n",
    "    # get travel times of waves from rift endpoint to each regional station\n",
    "    tt = travel_time(0,rift_end_x_y[0],rift_end_x_y[1],phase_velocity,x_y[0],x_y[1])\n",
    "    metadata[stat]['travel time'] = tt\n",
    "      \n",
    "    # get window start and end times at each regional station\n",
    "    metadata[stat]['starttime'] = starttime + metadata[stat]['travel time']\n",
    "    metadata[stat]['endtime'] = endtime + metadata[stat]['travel time']\n",
    "        \n",
    "    # get angle from regional stations to each rift endpoint and take average\n",
    "    angle_start = np.arctan2(x_y[1]-rift_start_x_y[1],x_y[0]-rift_start_x_y[0])*180/np.pi\n",
    "    angle_end = np.arctan2(x_y[1]-rift_end_x_y[1],x_y[0]-rift_end_x_y[0])*180/np.pi\n",
    "    angle = np.mean((angle_start,angle_end))\n",
    "    if angle < 0:\n",
    "        angle = 180+angle\n",
    "        metadata[stat]['position'] = 'front'\n",
    "    else:\n",
    "        metadata[stat]['position'] = 'back'\n",
    "        \n",
    "    # get angle between rift path and station\n",
    "    metadata[stat]['theta'] = np.abs(propagation_angle-angle)\n",
    "    \n",
    "# get seismic data from local stations\n",
    "st_local.trim(starttime=metadata[local_stations[0]]['starttime'],endtime=metadata[local_stations[0]]['endtime'])\n",
    "if component in [\"R\",\"T\"]:\n",
    "    baz_file = open('outputs/locations/PIG2_PIG4_PIG5_backazimuth.pickle', \"rb\")\n",
    "    b = pickle.load(baz_file)\n",
    "    backazimuth = b.backazimuths\n",
    "    baz_file.close()\n",
    "    st_local.rotate('NE->RT',backazimuth)\n",
    "local_data = st_local.select(component=component)[0].data\n",
    "\n",
    "# get characteristic frequency from local station\n",
    "f_source = get_characteristic_frequency(local_data,fs,freq,\"fft\",\"mean\")\n",
    "metadata[local_stations[0]]['f'] = f_source\n",
    "\n",
    "# make object for results\n",
    "results = {}\n",
    "\n",
    "# perform the Doppler analysis for each local-regional station pair\n",
    "for stat in regional_stations:\n",
    "    # get seismic data from regional station\n",
    "    st_station = st_regional.copy().select(station = stat)\n",
    "    st_station.trim(starttime=metadata[stat]['starttime'],endtime=metadata[stat]['endtime'])\n",
    "    if component in [\"R\",\"T\"]:\n",
    "        baz_file = open('outputs/locations/' + stat + '_backazimuth.pickle', \"rb\")\n",
    "        b = pickle.load(baz_file)\n",
    "        backazimuth = b.backazimuths\n",
    "        baz_file.close()\n",
    "        st_station.rotate('NE->RT',backazimuth)\n",
    "    regional_data = st_station.select(component=component)[0].data\n",
    "    \n",
    "    # get characteristic frequency from regional station\n",
    "    f_station = get_characteristic_frequency(regional_data,fs,freq,\"fft\",\"mean\")\n",
    "    metadata[stat]['f'] = f_station\n",
    "    \n",
    "    # get characteristic frequency from regional station and calculate source velocity\n",
    "    if metadata[stat]['position'] == 'front':\n",
    "        v_s = (phase_velocity * (1 - f_source/f_station)) / np.cos(metadata[stat]['theta']*np.pi/180)\n",
    "    if metadata[stat]['position'] == 'back':\n",
    "        v_s = (phase_velocity * (f_source/f_station - 1)) / np.cos(metadata[stat]['theta']*np.pi/180)\n",
    "    results[local_stations[0] + \"_\" + stat] = v_s\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Plot spectra through time at local station to identify clearest spectral peak\n",
    "\n",
    "'''\n",
    "\n",
    "# read data\n",
    "resp = \"VEL\"\n",
    "component = \"Z\"\n",
    "st = obspy.read(\"data/MSEED/no_IR/*/*/2012-05-09*\"+resp+\"*\")\n",
    "\n",
    "# set frequency band for analysis\n",
    "freq = [1,5]\n",
    "fs = 40\n",
    "\n",
    "# set starttime and endtime for analysis\n",
    "starttime=obspy.UTCDateTime(2012,5,9,18,2)\n",
    "endtime=obspy.UTCDateTime(2012,5,9,18,10)\n",
    "\n",
    "# select, filter, and trim local data\n",
    "stations = [\"PIG2\",\"PIG4\",\"PIG5\",\"THUR\",\"DNTW\",\"UPTW\"]\n",
    "st = taper_and_filter(st,0.05,\"bandpass\",freq)\n",
    "st.trim(starttime=starttime,endtime=endtime)\n",
    "st.resample(fs)\n",
    "\n",
    "# iterate through time\n",
    "win_size = 30\n",
    "for station in stations:\n",
    "    st_station = st.select(station=station)\n",
    "    windowed_normalized_psd(st_station,win_size,freq,starttime,endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Estimate rift tip velocity using Doppler shift between local stations and each regional station\n",
    "\n",
    "'''\n",
    "\n",
    "# read data\n",
    "resp = \"VEL\"\n",
    "component = \"Z\"\n",
    "st = obspy.read(\"data/MSEED/no_IR/*/*/2012-05-09*\"+resp+\"*\")\n",
    "\n",
    "# set frequency band for analysis\n",
    "freq = [1,5]\n",
    "\n",
    "# select, filter, and trim regional data\n",
    "stations = ['DNTW','UPTW','THUR']\n",
    "network = 'YT'\n",
    "st_regional = obspy.Stream()\n",
    "for stat in stations:\n",
    "    st_regional += st.select(station=stat)\n",
    "st_regional = taper_and_filter(st_regional,0.05,\"bandpass\",freq)\n",
    "fs = st_regional[0].stats.sampling_rate\n",
    "\n",
    "# make object for storing values needed for Doppler analysis\n",
    "metadata = {}\n",
    "for stat in stations:\n",
    "    metadata[stat] = {}\n",
    "    metadata[stat]['network'] = network\n",
    "        \n",
    "# select time window for Doppler analysis\n",
    "starttime = obspy.UTCDateTime(2012,5,9,18,6)\n",
    "endtime = obspy.UTCDateTime(2012,5,9,18,8)\n",
    "\n",
    "# define rift start and end positions in longitude and latitude\n",
    "rift_start_lon_lat = [-101.224, -74.867]\n",
    "rift_end_lon_lat = [-101.16, -74.955]\n",
    "\n",
    "# set phase velocity\n",
    "phase_velocity = 4000\n",
    "\n",
    "# set window size in seconds\n",
    "win_size = 60\n",
    "\n",
    "# convert rift endpoints to epsg:3245\n",
    "rift_start_x_y = get_crs_locations(np.array([rift_start_lon_lat]),\"EPSG:3245\").flatten()\n",
    "rift_end_x_y = get_crs_locations(np.array([rift_end_lon_lat]),\"EPSG:3245\").flatten()\n",
    "\n",
    "# get angle of rift propagation\n",
    "propagation_angle = np.arctan2(rift_start_x_y[1]-rift_end_x_y[1],rift_start_x_y[0]-rift_end_x_y[0])*180/np.pi\n",
    "\n",
    "# get useful metadata for Doppler analysis\n",
    "for stat in stations:\n",
    "    \n",
    "    # get station locations\n",
    "    lon_lat = get_station_lon_lat(\"data/XML/\",[metadata[stat]['network']],[stat])\n",
    "    x_y = get_crs_locations(lon_lat,\"epsg:3245\")[0]\n",
    "    metadata[stat]['lon lat'] = lon_lat\n",
    "    metadata[stat]['x y'] = x_y\n",
    "    \n",
    "    # get station distance from PIG\n",
    "    pig_lon_lat = get_station_lon_lat(\"data/XML/\",[\"XC\"],[\"PIG2\"])\n",
    "    pig_x_y = get_crs_locations(pig_lon_lat,\"epsg:3245\")[0]\n",
    "    metadata[stat]['distance'] = np.sqrt(np.sum(np.square(x_y - pig_x_y)))\n",
    "    \n",
    "    # get travel times of waves from rift endpoint to each regional station\n",
    "    tt = travel_time(0,rift_end_x_y[0],rift_end_x_y[1],phase_velocity,x_y[0],x_y[1])\n",
    "    metadata[stat]['travel time'] = tt\n",
    "      \n",
    "    # get window start and end times at each regional station\n",
    "    metadata[stat]['starttime'] = starttime# + metadata[stat]['travel time']\n",
    "    metadata[stat]['endtime'] = endtime# + metadata[stat]['travel time']\n",
    "\n",
    "    # get angle from regional stations to each rift endpoint and take average\n",
    "    angle_start = np.arctan2(x_y[1]-rift_start_x_y[1],x_y[0]-rift_start_x_y[0])*180/np.pi\n",
    "    angle_end = np.arctan2(x_y[1]-rift_end_x_y[1],x_y[0]-rift_end_x_y[0])*180/np.pi\n",
    "    angle = np.mean((angle_start,angle_end))\n",
    "    if angle < 0:\n",
    "        angle = 180+angle\n",
    "        metadata[stat]['position'] = 'front'\n",
    "    else:\n",
    "        metadata[stat]['position'] = 'back'\n",
    "        \n",
    "    # get angle between rift path and station\n",
    "    metadata[stat]['theta'] = np.abs(propagation_angle-angle)\n",
    "\n",
    "# make object for results\n",
    "results = {}\n",
    "for stat in stations:\n",
    "    results[stat] = {}\n",
    "    \n",
    "# calculate characteristic frequency for each station\n",
    "for stat in stations:\n",
    "    \n",
    "    # get seismic data from regional station\n",
    "    st_station = st_regional.copy().select(station = stat)\n",
    "    st_station.trim(starttime=metadata[stat]['starttime'],endtime=metadata[stat]['endtime'])\n",
    "    if component in [\"R\",\"T\"]:\n",
    "        baz_file = open('outputs/locations/' + stat + '_backazimuth.pickle', \"rb\")\n",
    "        b = pickle.load(baz_file)\n",
    "        backazimuth = b.backazimuths\n",
    "        baz_file.close()\n",
    "        st_station.rotate('NE->RT',backazimuth)\n",
    "    regional_data = st_station.select(component=component)[0].data\n",
    "    \n",
    "    # iterate through the data in windows and measure characteristic frequency\n",
    "    win_size_samples = int(win_size*fs)\n",
    "    f = []\n",
    "    for w in range(len(regional_data)-win_size_samples):\n",
    "        windowed_data = regional_data[w:w+win_size_samples]\n",
    "    \n",
    "        # get characteristic frequency from regional station\n",
    "        f.append(get_characteristic_frequency(windowed_data,fs,freq,\"fft\",\"mean\"))\n",
    "    \n",
    "    # save results\n",
    "    results[stat]['f'] = f\n",
    "    \n",
    "# # perform the Doppler analysis for each front-back station pair\n",
    "# for stat in stations:\n",
    "#     if metadata[stat]['position'] == 'back':\n",
    "#         f_b = metadata[stat]['f']\n",
    "#         theta_b = metadata[stat]['theta']\n",
    "        \n",
    "# for stat in stations:\n",
    "#     if metadata[stat]['position'] == 'front':\n",
    "#         f_f = metadata[stat]['f']\n",
    "#         theta_f = metadata[stat]['theta']\n",
    "#         v_s = (f_f-f_b)/(f_f*np.cos(theta_f*np.pi/180)+f_b*np.cos(theta_b*np.pi/180))*phase_velocity\n",
    "#         print(v_s)\n",
    "#\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plot of results\n",
    "fig,ax = plt.subplots(3,1,figsize=(9,7))\n",
    "bins = np.linspace(1.5,2,100)\n",
    "for i in range(len(stations)):\n",
    "    ax[i].hist(results[stations[i]][\"f\"],bins=bins)\n",
    "    ax[i].set_xlim(1.5,2)\n",
    "    f_mean = np.median(results[stations[i]][\"f\"])\n",
    "    results[stations[i]]['f_mean'] = f_mean\n",
    "    ax[i].axvline(f_mean,c='r',linestyle='--')\n",
    "    top_lim = ax[i].get_ylim()[1]\n",
    "    ax[i].text(f_mean+0.01,0.75*top_lim,\"f = \" + str(np.round(f_mean,3)) + \"Hz\",c='r')\n",
    "    if metadata[stations[i]]['position'] == 'front':\n",
    "        ax[i].set_title(stations[i] + \" (\" + str(np.round(metadata[stations[i]]['distance']/1000,2)) + \" km in front of rift path)\")\n",
    "    if metadata[stations[i]]['position'] == 'back':\n",
    "        ax[i].set_title(stations[i] + \" (\" + str(np.round(metadata[stations[i]]['distance']/1000,2)) + \" km behind rift path)\")\n",
    "\n",
    "ax[1].set_ylabel('Number of windows')\n",
    "ax[2].set_xlabel('Frequency (Hz)')\n",
    "\n",
    "plt.suptitle(\"Distribution of mean frequency (\" + component + \" data, \" + str(win_size) + \" second sliding windows)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# estimate source velocity\n",
    "f_b = results['THUR']['f_mean']\n",
    "theta_b = metadata['THUR']['theta']\n",
    "f_f = results['DNTW']['f_mean']\n",
    "theta_f = metadata['DNTW']['theta']\n",
    "v_s = (f_f-f_b)/(f_f*np.cos(theta_f*np.pi/180)+f_b*np.cos(theta_b*np.pi/180))*phase_velocity\n",
    "print(\"Predicted source velocity: \" + str(np.round(v_s,2)) + \" m/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7b122",
   "metadata": {},
   "source": [
    "# Relating rupture speed to Doppler shift at two stations\n",
    "\n",
    "\\begin{align}\n",
    "c = \\text{phase velocity}\\\\\n",
    "v_o = \\text{observer velocity}\\\\\n",
    "v_s = \\text{source velocity}\\\\\n",
    "f = \\text{true frequency}\\\\\n",
    "\\theta_f = \\text{angle between the propagation direction and observing stations in front of source}\\\\\n",
    "\\theta_b = \\text{angle between the propagation direction and observing stations behind source}\\\\\n",
    "\\\\\n",
    "\\text{In this case, all observing stations are distant enough that $\\theta_f$ and $\\theta_b$, the angles between the propagation}\\\\\n",
    "\\text{direction and the observing stations in front and behind the source, can be considered constant.}\\\\\n",
    "\\\\\n",
    "\\text{In front of rift:} \\hspace{0.5cm} f_{front} = f_f = \\frac{c + v_o}{c - v_scos\\theta_f} f\\\\\n",
    "\\text{Behind rift:} \\hspace{0.5cm} f_{behind} = f_b = \\frac{c + v_o}{c + v_scos\\theta_b} f\\\\\n",
    "\\text{Observer velocity is zero:} \\hspace{0.5cm} f_f = \\frac{c}{c-v_scos\\theta_f}f \\hspace{0.5cm} \\text{and} \\hspace{0.5cm} f_b = \\frac{c}{c+v_scos\\theta_b}f\\\\\n",
    "\\frac{f_f}{f_b} = \\left(\\frac{c}{c-v_scos\\theta_f}f\\right) \\div \\left(\\frac{c}{c+v_scos\\theta_b}f\\right)\\\\\n",
    "\\frac{f_f}{f_b} = \\frac{c+v_scos\\theta_b}{c-v_scos\\theta_f}\\\\\n",
    "f_f(c-v_scos\\theta_f) = f_b(c+v_scos\\theta_b)\\\\\n",
    "f_fc-f_fv_scos\\theta_f = f_bc+f_bv_scos\\theta_b\\\\\n",
    "f_fc - f_bc = f_fv_scos\\theta_f+f_bv_scos\\theta_b\\\\\n",
    "c(f_f - f_b) = v_s(f_fcos\\theta_f+f_bcos\\theta_b)\\\\\n",
    "v_s = c\\frac{f_f-f_b}{f_fcos\\theta_f+f_bcos\\theta_b}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Calculate backazimuth at each regional station\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# initialize location parameter object and set parameters for backazimuth computation\n",
    "l = types.SimpleNamespace()\n",
    "l.win_len = 50\n",
    "l.slide = 5\n",
    "l.trace_len = 4*60\n",
    "l.num_steps = int((l.trace_len-l.win_len)/l.slide)+1\n",
    "stations = [\"THUR\",\"UPTW\",\"DNTW\"]\n",
    "l.network = [\"YT\"]\n",
    "\n",
    "# specify whether to use velocity or displacement seismogram\n",
    "l.response = \"VEL\"\n",
    "\n",
    "# specify path to data, XML, and output\n",
    "l.data_path = \"data/MSEED/no_IR\"\n",
    "l.xml_path = \"data/XML\"\n",
    "l.n_procs = 10\n",
    "\n",
    "# set event start time\n",
    "event_start = datetime.datetime(2012, 5, 9, 18, 3)\n",
    "event_end = event_start + datetime.timedelta(seconds=l.trace_len)\n",
    "l.detection_times = np.array([event_start])\n",
    "\n",
    "# set the coordinate system in which we will do all grid-based calculations\n",
    "l.crs = \"EPSG:3245\"\n",
    "\n",
    "# set signal-to-noise ratio for throwing out stations and sta/lta ratio for throwing out individual windows in backazimuth computation\n",
    "l.snr_threshold = 0\n",
    "l.stalta_threshold = 0\n",
    "\n",
    "# specify method for correcting pca components \n",
    "l.pca_correction = \"manual\"\n",
    "flip = [True,True,True]\n",
    "l.centroid = \"fixed\"\n",
    "\n",
    "# specify parameters for cross correlation based determination of station of first arrival\n",
    "l.max_shift = 1000\n",
    "\n",
    "# set frequency band for backazimuth calculation\n",
    "l.fs = 40\n",
    "l.freq = [1,5]\n",
    "\n",
    "# calculate backazimuth for the event\n",
    "for i in range(len(stations)):\n",
    "    l.stations = [stations[i]]\n",
    "    l.flip = flip[i]\n",
    "    l.filename = \"outputs/locations/\" + \"_\".join(l.stations) + \"_backazimuth\"\n",
    "    b = compute_backazimuths(l)\n",
    "    print(str(b) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067f339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sermeq_env",
   "language": "python",
   "name": "sermeq_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
